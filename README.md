# Анализ защищенности систем искусственного интеллекта

Практические работы:

[Практика 1](https://github.com/AntonOcheredko/AZSII/tree/main/Pr1/) Установка окружения и настройка фреймворков для анализа защищенности ИИ

[Практика 2](https://github.com/AntonOcheredko/AZSII/tree/main/Pr2/) Исследование атак на модели ИИ. Fast Gradient Sign Method (FGSM)

[Практика 3](https://github.com/AntonOcheredko/AZSII/tree/main/Pr3/) Атака Carlini-Wagner (CW) на модели ИИ

[Практика 4](https://github.com/AntonOcheredko/AZSII/tree/main/Pr4/) Атака DeepFool на модели ИИ

[Практика 5](https://github.com/AntonOcheredko/AZSII/tree/main/Pr5/) Атака с ограниченной памятью (PGD - Projected Gradient Descent)

[Практика 6](https://github.com/AntonOcheredko/AZSII/tree/main/Pr6/) Атака по переносу (Transfer Attack) на модели ИИ

[Практика 7](https://github.com/AntonOcheredko/AZSII/tree/main/Pr7/) Создание и использование генеративных противоречивых примеров (GAN- based Adversarial Examples)

[Практика 8](https://github.com/AntonOcheredko/AZSII/tree/main/Pr8/) Методы защиты от атак на модели ИИ

Лабораторные работы.

[Лабораторная работа 1](https://github.com/AntonOcheredko/AZSII/tree/main/Lab1) 

[Лабораторная работа 2](https://github.com/AntonOcheredko/AZSII/tree/main/Lab2) 
